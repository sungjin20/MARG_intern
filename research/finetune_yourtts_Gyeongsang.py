import os
import torch
from trainer import Trainer, TrainerArgs
from TTS.config.shared_configs import BaseDatasetConfig
from TTS.tts.configs.vits_config import VitsConfig
from TTS.tts.datasets import load_tts_samples
from TTS.tts.models.vits import CharactersConfig, Vits, VitsArgs, VitsAudioConfig
import json

# ì‹¤í–‰ì„ ìœ„í•œ ì´ë¦„
RUN_NAME = "YourTTS-ko-ft-Gyeongsang"

# ëª¨ë¸ ì¶œë ¥(êµ¬ì„±, ì²´í¬í¬ì¸íŠ¸, í…ì„œë³´ë“œ ë¡œê·¸)ì„ ì €ì¥í•  ê²½ë¡œ
OUT_PATH = '/data2/personal/sungjin/korean_standard'  # "/raid/coqui/Checkpoints/original-YourTTS/"

RESTORE_PATH = '/data2/personal/sungjin/korean_standard/checkpoint_280000.pth'

# í•™ìŠµ ë° í‰ê°€ì— ì‚¬ìš©í•  ë°°ì¹˜ í¬ê¸°ë¥¼ ì—¬ê¸°ì—ì„œ ì„¤ì •í•©ë‹ˆë‹¤.
BATCH_SIZE = 28

SAMPLE_RATE = 16000

# í•™ìŠµì— ì‚¬ìš©ë˜ëŠ” ìµœëŒ€ ì˜¤ë””ì˜¤ ê¸¸ì´(ì´ˆ ë‹¨ìœ„). ì´ë³´ë‹¤ í° ì˜¤ë””ì˜¤ëŠ” ë¬´ì‹œë©ë‹ˆë‹¤.
MAX_AUDIO_LEN_IN_SECONDS = 6

# êµ¬ì„± ì´ˆê¸°í™”
Gyeongsang_data_config = BaseDatasetConfig(
    formatter="kdd",
    dataset_name="korean_dialects_dataset_Gyeongsang",
    meta_file_train="Gyeongsang_speech_trainset.txt",
    meta_file_val="Gyeongsang_speech_validset.txt",
    path='/data2/personal/sungjin/korean_dialects/modified/Gyeongsang',
    language="Gyeongsang",
)

DATASETS_CONFIG_LIST = [Gyeongsang_data_config]

D_VECTOR_FILES = []  # í•™ìŠµ ì¤‘ì— ì‚¬ìš©í•  ìŠ¤í”¼ì»¤ ì„ë² ë”©/d-ë²¡í„° ëª©ë¡

D_VECTOR_FILES.append("/data2/personal/sungjin/korean_dialects/speakers_mixed.json")

# í•™ìŠµì— ì‚¬ìš©ë˜ëŠ” ì˜¤ë””ì˜¤ êµ¬ì„±
audio_config = VitsAudioConfig(
    sample_rate=SAMPLE_RATE,
    hop_length=256,
    win_length=1024,
    fft_size=1024,
    mel_fmin=0,
    mel_fmax=8000,
    num_mels=80,
)

# YourTTS ëª¨ë¸ì— í•„ìš”í•œ ë§¤ê°œë³€ìˆ˜ë¥¼ ì„¤ì •í•˜ì—¬ VITSArgs ì´ˆê¸°í™”
model_args = VitsArgs(
    d_vector_file=D_VECTOR_FILES,
    use_d_vector_file=True,
    d_vector_dim=192,
    num_layers_text_encoder=10,
    hidden_channels=196,
    num_layers_flow=4,
    resblock_type_decoder="1",
    # ë‹¤êµ­ì–´ í•™ìŠµì„ í™œì„±í™”í•˜ëŠ” ë° ìœ ìš©í•œ ë§¤ê°œë³€ìˆ˜
    use_language_embedding=True,
    embedded_language_dim=64,
    num_languages=6
)

phoneme_cache_folder_path = '/home/research/phoneme_cache_ft_Gyeongsang'

# ì¼ë°˜ í•™ìŠµ êµ¬ì„±. ì—¬ê¸°ì—ì„œ ë°°ì¹˜ í¬ê¸° ë° ê¸°íƒ€ ìœ ìš©í•œ ë§¤ê°œë³€ìˆ˜ë¥¼ ë³€ê²½í•  ìˆ˜ ìˆìŒ
config = VitsConfig(
    output_path=OUT_PATH,
    model_args=model_args,
    run_name=RUN_NAME,
    project_name="YourTTS",
    run_description="",
    dashboard_logger="tensorboard",
    logger_uri=None,
    audio=audio_config,
    batch_size=BATCH_SIZE,
    batch_group_size=48,
    eval_batch_size=BATCH_SIZE,
    num_loader_workers=8,
    print_step=25,
    plot_step=100,
    log_model_step=1000,
    save_step=20000,
    save_n_checkpoints=10,
    save_checkpoints=True,
    target_loss="loss_1",
    print_eval=False,
    use_phonemes=True,
    phonemizer="ko_kr_phonemizer",
    compute_input_seq_cache=True,
    add_blank=False,
    characters=CharactersConfig(
        pad="_",
        eos="&",
        bos="*",
        blank=None,
        characters="á„€á„á„‚á„ƒá„„á„…á„†á„‡á„ˆá„‰á„Šá„‹á„Œá„á„á„á„á„‘á„’á…¡á…¢á…£á…¤á…¥á…¦á…§á…¨á…©á…ªá…«á…¬á…­á…®á…¯á…°á…±á…²á…³á…´á…µá†¨á†©á†ªá†«á†¬á†­á†®á†¯á†°á†±á†²á†³á†´á†µá†¶á†·á†¸á†¹á†ºá†»á†¼á†½á†¾á†¿á‡€á‡á‡‚",
        punctuations=".,!?~ ",
        is_unique=True,
        is_sorted=True,
    ),
    phoneme_cache_path=phoneme_cache_folder_path,
    precompute_num_workers=12,
    start_by_longest=True,
    datasets=DATASETS_CONFIG_LIST,
    cudnn_benchmark=False,
    max_audio_len=SAMPLE_RATE * MAX_AUDIO_LEN_IN_SECONDS,
    mixed_precision=False,
    test_sentences=[
        [
            "ì œ ë‚˜ì´ê°€ ì˜¬í•´ë¡œ ìŠ¤ë¬¼ë„¤ì‚´ì…ë‹ˆë‹¤.",
            "DKSR20000230_1",
            None,
            "Gyeongsang",
        ],
    ],
    # It defines the Speaker Consistency Loss (SCL) Î± to 9 like the paper
    speaker_encoder_loss_alpha=9.0,
)

data_dir = "/data2/personal/sungjin/quick_load_samples"
regions = ["Gyeongsang"]
train_samples = []
eval_samples = []
for region in regions:
    train_path = os.path.join(data_dir, f"{region}_train_samples.json")
    eval_path = os.path.join(data_dir, f"{region}_eval_samples.json")
    with open(train_path, "r", encoding="utf-8") as train_file:
        train_samples += json.load(train_file)
    with open(eval_path, "r", encoding="utf-8") as eval_file:
        eval_samples += json.load(eval_file)

# ëª¨ë¸ ì´ˆê¸°í™”
model = Vits.init_from_config(config)

# í•™ìŠµê¸° ì´ˆê¸°í™” ë° ğŸš€ ì‹œì‘
trainer = Trainer(
    #TrainerArgs(continue_path='/data2/personal/sungjin/korean_standard/YourTTS-ko-standard-February-06-2025_04+11PM-0000000', gpu=2), # gpuë²ˆí˜¸ ì„¤ì •
    TrainerArgs(restore_path=RESTORE_PATH, gpu=5), # gpuë²ˆí˜¸ ì„¤ì •
    config,  # ëª¨ë¸ êµ¬ì„±
    output_path=OUT_PATH,  # ì¶œë ¥ ê²½ë¡œ
    model=model,  # ëª¨ë¸ ê°ì²´
    train_samples=train_samples,  # í•™ìŠµ ìƒ˜í”Œ
    eval_samples=eval_samples,  # í‰ê°€ ìƒ˜í”Œ
)
trainer.fit()  # í•™ìŠµ ì‹œì‘